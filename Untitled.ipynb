{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e51814a-e539-491a-b403-7dbb2d1b07cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"alllines.txt\",'r',encoding='utf-8') as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7825bac8-dcf9-483e-ba68-3ba1149fc794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ACT I\"\n",
      "\"SCENE I. London. The palace.\"\n",
      "\"Enter KING HENRY, LORD JOHN OF LANCASTER, the EARL of WESTMORELAND, SIR WALTER BLUNT, and others\"\n",
      "\"So shaken as we are, so wan with care,\"\n",
      "\"Find we a time for frighted peace to pant,\"\n",
      "\"And breathe short-winded accents of new broils\"\n",
      "\"To be commenced in strands afar remote.\"\n",
      "\"No more the thirsty entrance of this soil\"\n",
      "\"Shall daub her lips with her own children's blood,\"\n",
      "\"Nor more shall trenching war channel her fields,\"\n",
      "\"Nor bruise her flowerets with the armed hoofs\"\n",
      "\"Of hostile paces: those opposed eyes,\"\n",
      "\"Which, like the meteors of a troubled heaven,\"\n",
      "\"All of one nature, of one substance bred,\"\n",
      "\"Did lately meet in the intestine shock\"\n",
      "\"And furious close of civil butchery\"\n",
      "\"Shall now, in mutual well-beseeming ranks,\"\n",
      "\"March all one way and be no more opposed\"\n",
      "\"Against acquaintance, kindred and allies:\"\n",
      "\"The edge of war, like an ill-sheathed knife,\"\n",
      "\"No more shall cut his master. Therefore, friends,\"\n",
      "\"As far as to the sepulchre of Christ,\"\n",
      "\"Whose \n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb5e8e8-046f-4b50-aa69-2b7cd9d69ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t\\n !\"$\\'(),-.0123456789:?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars=sorted(list(set(text)))\n",
    "vocab=''.join(chars)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f0bbbea-d0b0-4984-ad86-ba4d1b7b33d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57, 72, 54, 62, 2, 66, 57, 57]\n",
      "fuck off\n"
     ]
    }
   ],
   "source": [
    "#Create a mapping from charactors to integers\n",
    "\n",
    "stoi={ch:i for i,ch in enumerate(chars)}\n",
    "itos={i:ch for i,ch in enumerate(chars)}\n",
    "encode=lambda s:[stoi[c] for c in s]\n",
    "decode=lambda n: ''.join([itos[i] for i in n])\n",
    "\n",
    "print(encode(\"fuck off\"))\n",
    "print(decode([57, 72, 54, 62, 2, 66, 57, 57]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c2f325e-20a3-49e0-a4f1-25b09f895565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#google sentence piece\n",
    "#openAI uses tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2ec3879-74c3-4098-a1f4-20e9579b7906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data=torch.tensor(encode(text),dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "953c0e06-a361-40ae-aa42-3febd1ab7c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4583798]) <built-in method type of Tensor object at 0x1131e94a0>\n",
      "tensor([ 4, 24, 26, 43,  2, 32,  4,  1,  4, 42, 26, 28, 37, 28,  2, 32, 11,  2,\n",
      "        35, 66, 65, 55, 66, 65, 11,  2, 43, 59, 56,  2, 67, 52, 63, 52, 54, 56,\n",
      "        11,  4,  1,  4, 28, 65, 71, 56, 69,  2, 34, 32, 37, 30,  2, 31, 28, 37,\n",
      "        41, 48,  9,  2, 35, 38, 41, 27,  2, 33, 38, 31, 37,  2, 38, 29,  2, 35,\n",
      "        24, 37, 26, 24, 42, 43, 28, 41,  9,  2, 71, 59, 56,  2, 28, 24, 41, 35,\n",
      "         2, 66, 57,  2, 46, 28, 42, 43, 36, 38, 41, 28, 35, 24, 37, 27,  9,  2,\n",
      "        42, 32, 41,  2, 46, 24, 35, 43, 28, 41,  2, 25, 35, 44, 37, 43,  9,  2,\n",
      "        52, 65, 55,  2, 66, 71, 59, 56, 69, 70,  4,  1,  4, 42, 66,  2, 70, 59,\n",
      "        52, 62, 56, 65,  2, 52, 70,  2, 74, 56,  2, 52, 69, 56,  9,  2, 70, 66,\n",
      "         2, 74, 52, 65,  2, 74, 60, 71, 59,  2, 54, 52, 69, 56,  9,  4,  1,  4,\n",
      "        29, 60, 65, 55,  2, 74, 56,  2, 52,  2, 71, 60, 64, 56,  2, 57, 66, 69,\n",
      "         2, 57, 69, 60, 58, 59, 71, 56, 55,  2, 67, 56, 52, 54, 56,  2, 71, 66,\n",
      "         2, 67, 52, 65, 71,  9,  4,  1,  4, 24, 65, 55,  2, 53, 69, 56, 52, 71,\n",
      "        59, 56,  2, 70, 59, 66, 69, 71, 10, 74, 60, 65, 55, 56, 55,  2, 52, 54,\n",
      "        54, 56, 65, 71, 70,  2, 66, 57,  2, 65, 56, 74,  2, 53, 69, 66, 60, 63,\n",
      "        70,  4,  1,  4, 43, 66,  2, 53, 56,  2, 54, 66, 64, 64, 56, 65, 54, 56,\n",
      "        55,  2, 60, 65,  2, 70, 71, 69, 52, 65, 55, 70,  2, 52, 57, 52, 69,  2,\n",
      "        69, 56, 64, 66, 71, 56, 11,  4,  1,  4, 37, 66,  2, 64, 66, 69, 56,  2,\n",
      "        71, 59, 56,  2, 71, 59, 60, 69, 70, 71, 76,  2, 56, 65, 71, 69, 52, 65,\n",
      "        54, 56,  2, 66, 57,  2, 71, 59, 60, 70,  2, 70, 66, 60, 63,  4,  1,  4,\n",
      "        42, 59, 52, 63, 63,  2, 55, 52, 72, 53,  2, 59, 56, 69,  2, 63, 60, 67,\n",
      "        70,  2, 74, 60, 71, 59,  2, 59, 56, 69,  2, 66, 74, 65,  2, 54, 59, 60,\n",
      "        63, 55, 69, 56, 65,  6, 70,  2, 53, 63, 66, 66, 55,  9,  4,  1,  4, 37,\n",
      "        66, 69,  2, 64, 66, 69, 56,  2, 70, 59, 52, 63, 63,  2, 71, 69, 56, 65,\n",
      "        54, 59, 60, 65, 58,  2, 74, 52, 69,  2, 54, 59, 52, 65, 65, 56, 63,  2,\n",
      "        59, 56, 69,  2, 57, 60, 56, 63, 55, 70,  9,  4,  1,  4, 37, 66, 69,  2,\n",
      "        53, 69, 72, 60, 70, 56,  2, 59, 56, 69,  2, 57, 63, 66, 74, 56, 69, 56,\n",
      "        71, 70,  2, 74, 60, 71, 59,  2, 71, 59, 56,  2, 52, 69, 64, 56, 55,  2,\n",
      "        59, 66, 66, 57, 70,  4,  1,  4, 38, 57,  2, 59, 66, 70, 71, 60, 63, 56,\n",
      "         2, 67, 52, 54, 56, 70, 22,  2, 71, 59, 66, 70, 56,  2, 66, 67, 67, 66,\n",
      "        70, 56, 55,  2, 56, 76, 56, 70,  9,  4,  1,  4, 46, 59, 60, 54, 59,  9,\n",
      "         2, 63, 60, 62, 56,  2, 71, 59, 56,  2, 64, 56, 71, 56, 66, 69, 70,  2,\n",
      "        66, 57,  2, 52,  2, 71, 69, 66, 72, 53, 63, 56, 55,  2, 59, 56, 52, 73,\n",
      "        56, 65,  9,  4,  1,  4, 24, 63, 63,  2, 66, 57,  2, 66, 65, 56,  2, 65,\n",
      "        52, 71, 72, 69, 56,  9,  2, 66, 57,  2, 66, 65, 56,  2, 70, 72, 53, 70,\n",
      "        71, 52, 65, 54, 56,  2, 53, 69, 56, 55,  9,  4,  1,  4, 27, 60, 55,  2,\n",
      "        63, 52, 71, 56, 63, 76,  2, 64, 56, 56, 71,  2, 60, 65,  2, 71, 59, 56,\n",
      "         2, 60, 65, 71, 56, 70, 71, 60, 65, 56,  2, 70, 59, 66, 54, 62,  4,  1,\n",
      "         4, 24, 65, 55,  2, 57, 72, 69, 60, 66, 72, 70,  2, 54, 63, 66, 70, 56,\n",
      "         2, 66, 57,  2, 54, 60, 73, 60, 63,  2, 53, 72, 71, 54, 59, 56, 69, 76,\n",
      "         4,  1,  4, 42, 59, 52, 63, 63,  2, 65, 66, 74,  9,  2, 60, 65,  2, 64,\n",
      "        72, 71, 72, 52, 63,  2, 74, 56, 63, 63, 10, 53, 56, 70, 56, 56, 64, 60,\n",
      "        65, 58,  2, 69, 52, 65, 62, 70,  9,  4,  1,  4, 36, 52, 69, 54, 59,  2,\n",
      "        52, 63, 63,  2, 66, 65, 56,  2, 74, 52, 76,  2, 52, 65, 55,  2, 53, 56,\n",
      "         2, 65, 66,  2, 64, 66, 69, 56,  2, 66, 67, 67, 66, 70, 56, 55,  4,  1,\n",
      "         4, 24, 58, 52, 60, 65, 70, 71,  2, 52, 54, 68, 72, 52, 60, 65, 71, 52,\n",
      "        65, 54, 56,  9,  2, 62, 60, 65, 55, 69, 56, 55,  2, 52, 65, 55,  2, 52,\n",
      "        63, 63, 60, 56, 70, 22,  4,  1,  4, 43, 59, 56,  2, 56, 55, 58, 56,  2,\n",
      "        66, 57,  2, 74, 52, 69,  9,  2, 63, 60, 62, 56,  2, 52, 65,  2, 60, 63,\n",
      "        63, 10, 70, 59, 56, 52, 71, 59, 56, 55,  2, 62, 65, 60, 57, 56,  9,  4,\n",
      "         1,  4, 37, 66,  2, 64, 66, 69, 56,  2, 70, 59, 52, 63, 63,  2, 54, 72,\n",
      "        71,  2, 59, 60, 70,  2, 64, 52, 70, 71, 56, 69, 11,  2, 43, 59, 56, 69,\n",
      "        56, 57, 66, 69, 56,  9,  2, 57, 69, 60, 56, 65, 55, 70,  9,  4,  1,  4,\n",
      "        24, 70,  2, 57, 52, 69,  2, 52, 70,  2, 71, 66,  2, 71, 59, 56,  2, 70,\n",
      "        56, 67, 72, 63, 54, 59, 69, 56,  2, 66, 57,  2, 26, 59, 69, 60, 70, 71,\n",
      "         9,  4,  1,  4, 46, 59, 66, 70, 56,  2])\n"
     ]
    }
   ],
   "source": [
    "print(data.shape,data.type)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b26c0c0d-04ac-4e58-a304-3fb1a15db59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(0.9*len(data))\n",
    "train_data=data[:n]\n",
    "val_data=data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bf11158-8ba7-4b77-a06b-9708aab2bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size=8\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99efe812-077d-4625-8481-010b0741dd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[69, 52, 54, 60, 66, 72, 70,  2],\n",
      "        [60, 70,  2, 59, 60, 70,  2, 57],\n",
      "        [ 4,  1,  4, 67, 76, 69, 52, 64],\n",
      "        [56, 71,  9,  2, 71, 66,  2, 70]]) torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "def getbatch(Split):\n",
    "    data=train_data if Split=='train' else val_data\n",
    "    ix=torch.randint(len(data)-block_size,(batch_size,))\n",
    "    x=torch.stack([train_data[i:i+block_size] for i in ix ])\n",
    "    y=torch.stack([train_data[i+1:i+1+block_size] for i in ix ])\n",
    "\n",
    "    return x,y\n",
    "\n",
    "xb,yb=getbatch('train')\n",
    "print(xb\n",
    "      ,yb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e193ab9-a6ef-4492-8984-10f2114ae29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table=nn.Embedding(vocab_size,vocab_size)\n",
    "    def forward(self,idx,targets=None):\n",
    "        logits=self.token_embedding_table(idx)\n",
    "\n",
    "        if targets!=None:\n",
    "            B,T,C=logits.shape\n",
    "            logits=logits.view(B*T,C)\n",
    "            targets=targets.view(B*T)\n",
    "            loss=F.cross_entropy(logits,targets)\n",
    "        else:\n",
    "            loss=None\n",
    "        return logits,loss\n",
    "        \n",
    "    def genrate(self,idx,max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits,loss=self(idx)\n",
    "            logits=logits[:,-1,:]\n",
    "            probs=F.softmax(logits,dim=-1)\n",
    "\n",
    "            idx_next=torch.multinomial(probs,num_samples=1)\n",
    "            idx=torch.cat((idx,idx_next),dim=1)\n",
    "\n",
    "        return idx\n",
    "            \n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1bab67ea-3d99-4f20-84d9-b7c4bb611625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6372, -0.5970, -0.4255,  ..., -0.2200,  0.0422, -0.1580],\n",
      "        [-1.0707,  0.1294, -0.4570,  ..., -0.4476,  0.2270,  1.5843],\n",
      "        [-0.8500, -0.7722,  0.6353,  ...,  1.6345,  0.4233, -0.8747],\n",
      "        ...,\n",
      "        [-2.2905,  1.0941,  1.0316,  ...,  1.0642, -1.0928, -1.8385],\n",
      "        [-1.0572, -0.6543,  1.5909,  ..., -0.4474,  0.8204, -1.5178],\n",
      "        [ 1.1402, -1.5646, -0.8132,  ..., -0.8837,  0.5847, -0.2079]],\n",
      "       grad_fn=<ViewBackward0>) tensor(4.8167, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "m=BigramLanguageModel(len(vocab))\n",
    "logits,loss=m.forward(xb,yb)\n",
    "print(logits,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b1308413-d305-4ca4-bcdf-918aa4f28459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\tuw6\\'-jvRI\")$H]ljO4AjiRuBj,yA6yGtt\\'L:t(4?I1(\\n O-jyF5jt8xDHt5j[pH\\'vvf67(stP0xfgXN$HZCn9jh!:bJb6bLfYQkd'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=torch.zeros((1,1),dtype=torch.long)\n",
    "decode(m.genrate(idx,100)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ea74bb94-3071-4de6-868a-d6804ee1fb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8166584968566895"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "00d89476-e730-413d-8689-a6536c3193e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3825159072875977\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "optimizer=torch.optim.AdamW(m.parameters(),lr=1e-3)\n",
    "\n",
    "for _ in range(1000):\n",
    "    xb,yb=getbatch('train')\n",
    "    logits,loss=m.forward(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea8344d1-d44f-4627-b343-d072988aaa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMeayo nd h woug a\"Andraisop restaresife g ioutheie ity br, mashi,'s, y Dr I' plello tr ison fteallt\n",
      "\"Ay,\"\n",
      "\"\n",
      "\"Whinkn ite s,\"\n",
      "\"\n",
      "\"\n",
      "\"Gotl ly fouglly ir d CExealfurrinkermintitog eromou Thacho m f yok be tngry in d hy hant, autavyo oe, d and vours o cay tis s,\"\n",
      "\"Amitere povel corerened cknon diver.\"ANDand\"Whe oforaths! h us\"SCLef fan bet wom eshe llly bllo y ss.\"Fr as, lfasun ainse yowhe o histhed olfr wnns,\"Touloostel beme ol lay ererurtreers'lanis fye frthinged wir Whe?\"\n",
      "\"\n",
      "\"Exisinor vead avobistal th horale s prenl thes as, wedr yont htrequs Our he gite h f nd aure se r,\"Thaven at in tr m o melasours ars as m Coacer gd. bochonk br mesthes u:\"Nound?\"\n",
      "\"MAliday an grneard, t wicy: I lot illowis l ouloupefan--ndanourerees 'd an'ssinditlotturafispanse de ayof f aiumete, tr thee'd: e ws.\"\n",
      "\"\n",
      "\"Theal illtheryont be mey Horet illecy 'd scaveyont wraravem horicemire\"Toopardne, thaveset was he to prd\"\n",
      "\"\n",
      "\"\n",
      "\"\n",
      "\"\n",
      "\"UCO,\"\n",
      "\"WI theioriso h, y y st ad ollfofrrorganeratherape t fffeaprielerrevend Rithavent, s\"\n"
     ]
    }
   ],
   "source": [
    "idx=torch.zeros((1,1),dtype=torch.long)\n",
    "print(decode(m.genrate(idx,1000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d371e51-0c9b-46b2-878a-3ae743508d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myvenv)",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
